{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Ling x44 Week 4\n",
      "\n",
      "_You can find this notebook on my GitHub repo: http://github.com/obnorthrup/144coursework _  \n",
      "_Don't let me start until you're set up! You'll also need my `data` folder, which is different from the one on the course website._\n",
      "\n",
      "## Today's project\n",
      "\n",
      "We're going to load several text files, get word frequencies, filter common words out, and print some frequency results to a new file."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 1: Loading, tokenizing\n",
      "\n",
      "Let's load some text files and make a dictionary of word frequencies from them. What are the steps?\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Write a function break a text file into a list of words - tokenizeFle()\n",
      "    1. Load the file\n",
      "    2. Read the file line by line and find the words\n",
      "    3. Store the words in a list (with the words from all the other lines)\n",
      "    4. Return the list\n",
      "2. Write a function that finds every text file in path_to_dir and runs tokenizeFile() on it, then returns the resulkts of all those calls together.\n",
      "- tokenizeFir(path_to_dir)\n",
      "    \n",
      "    1. Find out what's in the directory\n",
      "    2. Limit ourselves to just the text file (.txt)\n",
      "    3. Call tokenizeFile() on each text file, glom it all together, and return"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.1 tokenizeFile()\n",
      "\n",
      "Let's start small. Load a file (grimm_snippet) and print it line-by-line."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.getcwd()\n",
      "\n",
      "path = \".\\data\\grimm_snippet.txt\"\n",
      "fb = open(path, \"r\")\n",
      "\n",
      "for line in fb:\n",
      "    print line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Then the gardener's eldest son set out and thought to find the golden\n",
        "\n",
        "bird very easily; and when he had gone but a little way, he came to a\n",
        "\n",
        "wood, and by the side of the wood he saw a fox sitting; so he took his\n",
        "\n",
        "bow and made ready to shoot at it. Then the fox said, 'Do not shoot me,\n",
        "\n",
        "for I will give you good counsel; I know what your business is, and\n",
        "\n",
        "that you want to find the golden bird. You will reach a village in the\n",
        "\n",
        "evening; and when you get there, you will see two inns opposite to each\n",
        "\n",
        "other, one of which is very pleasant and beautiful to look at: go not in\n",
        "\n",
        "there, but rest for the night in the other, though it may appear to you\n",
        "\n",
        "to be very poor and mean.' But the son thought to himself, 'What can\n",
        "\n",
        "such a beast as this know about the matter?' So he shot his arrow at\n",
        "\n",
        "the fox; but he missed it, and it set up its tail above its back and\n",
        "\n",
        "ran into the wood. Then he went his way, and in the evening came to\n",
        "\n",
        "the village where the two inns were; and in one of these were people\n",
        "\n",
        "singing, and dancing, and feasting; but the other looked very dirty,\n",
        "\n",
        "and poor. 'I should be very silly,' said he, 'if I went to that shabby\n",
        "\n",
        "house, and left this charming place'; so he went into the smart house,\n",
        "\n",
        "and ate and drank at his ease, and forgot the bird, and his country too.\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now let's find all the words in a string, using a regular expression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "silly = '''\"I should be very silly,\" said he, \"if I went to that shabby\n",
      "house, and left this charming place;\" so he went into the smart house,\n",
      "and ate and drank at his ease, and forgot the bird, and his country too.'''\n",
      "\n",
      "silly_list = re.findall(r\"[\\w']+\", silly)\n",
      "print silly_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['I', 'should', 'be', 'very', 'silly', 'said', 'he', 'if', 'I', 'went', 'to', 'that', 'shabby', 'house', 'and', 'left', 'this', 'charming', 'place', 'so', 'he', 'went', 'into', 'the', 'smart', 'house', 'and', 'ate', 'and', 'drank', 'at', 'his', 'ease', 'and', 'forgot', 'the', 'bird', 'and', 'his', 'country', 'too']\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Putting these together..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def tokenizeFile(path):\n",
      "    fb = open(path, \"r\")\n",
      "    wordList = []\n",
      "    for line in fb:\n",
      "        words = re.findall(\"[\\w']+\", line.lower())\n",
      "        wordList += words #not append, append returns a list of lists\n",
      "    return wordList\n",
      "    \n",
      "\n",
      "yourPath = \".\\data\\grimm_snippet.txt\"\n",
      "print tokenizeFile(yourPath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['then', 'the', \"gardener's\", 'eldest', 'son', 'set', 'out', 'and', 'thought', 'to', 'find', 'the', 'golden', 'bird', 'very', 'easily', 'and', 'when', 'he', 'had', 'gone', 'but', 'a', 'little', 'way', 'he', 'came', 'to', 'a', 'wood', 'and', 'by', 'the', 'side', 'of', 'the', 'wood', 'he', 'saw', 'a', 'fox', 'sitting', 'so', 'he', 'took', 'his', 'bow', 'and', 'made', 'ready', 'to', 'shoot', 'at', 'it', 'then', 'the', 'fox', 'said', \"'do\", 'not', 'shoot', 'me', 'for', 'i', 'will', 'give', 'you', 'good', 'counsel', 'i', 'know', 'what', 'your', 'business', 'is', 'and', 'that', 'you', 'want', 'to', 'find', 'the', 'golden', 'bird', 'you', 'will', 'reach', 'a', 'village', 'in', 'the', 'evening', 'and', 'when', 'you', 'get', 'there', 'you', 'will', 'see', 'two', 'inns', 'opposite', 'to', 'each', 'other', 'one', 'of', 'which', 'is', 'very', 'pleasant', 'and', 'beautiful', 'to', 'look', 'at', 'go', 'not', 'in', 'there', 'but', 'rest', 'for', 'the', 'night', 'in', 'the', 'other', 'though', 'it', 'may', 'appear', 'to', 'you', 'to', 'be', 'very', 'poor', 'and', 'mean', \"'\", 'but', 'the', 'son', 'thought', 'to', 'himself', \"'what\", 'can', 'such', 'a', 'beast', 'as', 'this', 'know', 'about', 'the', 'matter', \"'\", 'so', 'he', 'shot', 'his', 'arrow', 'at', 'the', 'fox', 'but', 'he', 'missed', 'it', 'and', 'it', 'set', 'up', 'its', 'tail', 'above', 'its', 'back', 'and', 'ran', 'into', 'the', 'wood', 'then', 'he', 'went', 'his', 'way', 'and', 'in', 'the', 'evening', 'came', 'to', 'the', 'village', 'where', 'the', 'two', 'inns', 'were', 'and', 'in', 'one', 'of', 'these', 'were', 'people', 'singing', 'and', 'dancing', 'and', 'feasting', 'but', 'the', 'other', 'looked', 'very', 'dirty', 'and', 'poor', \"'i\", 'should', 'be', 'very', 'silly', \"'\", 'said', 'he', \"'if\", 'i', 'went', 'to', 'that', 'shabby', 'house', 'and', 'left', 'this', 'charming', \"place'\", 'so', 'he', 'went', 'into', 'the', 'smart', 'house', 'and', 'ate', 'and', 'drank', 'at', 'his', 'ease', 'and', 'forgot', 'the', 'bird', 'and', 'his', 'country', 'too']\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1.2 tokenizeDir()\n",
      "\n",
      "Ok, now let's call this on multiple files. We'll 1) create a list of paths to text files in a particular directory and 2) loop through that list, running tokenizeFile() as we go.\n",
      "\n",
      "First up: List the text files in a directory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "pathList = [\".\\data\\chronoguide\", \".\\data\\grimm_snippet.txt\", \".\\data\\100_most_common.txt\", \".\\data\\100_most_common_challenge,txt\"]\n",
      "\n",
      "os.getcwd()\n",
      "#os.chdir(\"/Users/obn/Dropbox/Linguistics/Comp Methods/x44private/Section prep/\")\n",
      "for fyle in os.listdir(\".\"):\n",
      "    if fyle.endswith(\".txt\"):\n",
      "        print fyle\n",
      "#print os.listdir(\".\\data\\chronoguide\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 83
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, make a function called txtInDir(directory) that takes a path (to the `chronoguide` directory) and returns a list of all the text files in it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def txtInDir(directory):\n",
      "    paths= []\n",
      "    for fyle in os.listdir(directory):\n",
      "        if fyle.endswith(\".txt\"):\n",
      "            fylePath = directory + fyle\n",
      "            paths.append(fylePath)\n",
      "    return paths \n",
      "\n",
      "chronoDir = \".\\data\\chronoguide\"\n",
      "chronoFileList = txtInDir(chronoDir)\n",
      "print chronoFileList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['.\\\\data\\\\chronoguidechrono_trigger_1.txt', '.\\\\data\\\\chronoguidechrono_trigger_2.txt', '.\\\\data\\\\chronoguidechrono_trigger_3.txt']\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Almost there. We have a way to list text files and a way to tokenize a single text file. Write tokenizeDir(directory) to put these together."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import re\n",
      "\n",
      "def tokenizeDir(directory):\n",
      "    totalWords = []\n",
      "    pathList = txtInDir(directory)\n",
      "    print pathList\n",
      "    for path in pathList:\n",
      "        fileWords = tokenizeFile(path)\n",
      "        totalWords.extend(fileWords)\n",
      "    return totalWords\n",
      "    # Your code here\n",
      "\n",
      "\n",
      "chronoWords = tokenizeDir(chronoDir)\n",
      "print words[1895:2050]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: '.\\\\data\\\\chronoguidechrono_trigger_1.txt'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-85-89c12178fe62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mchronoWords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizeDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchronoDir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1895\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2050\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-85-89c12178fe62>\u001b[0m in \u001b[0;36mtokenizeDir\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mpathList\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpathList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mfileWords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizeFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mtotalWords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileWords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotalWords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-82-6394e6d68f0a>\u001b[0m in \u001b[0;36mtokenizeFile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenizeFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mwordList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '.\\\\data\\\\chronoguidechrono_trigger_1.txt'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['.\\\\data\\\\chronoguidechrono_trigger_1.txt', '.\\\\data\\\\chronoguidechrono_trigger_2.txt', '.\\\\data\\\\chronoguidechrono_trigger_3.txt']\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 2: Frequencies\n",
      "\n",
      "Let's make a dictionary of word frequencies from chronoWords. Steps:\n",
      "\n",
      "1. Initialize a dictionary\n",
      "2. Loop through chronoWords\n",
      "    1. If a word is in the dictionary, increment its value\n",
      "    2. If a word isn't in the dictionary, add it with value 1"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def words2freq(wordList):\n",
      "    frequencies = {}\n",
      "    # Your code here. How do we loop through the words in the 'words' list?\n",
      "    return frequencies\n",
      "\n",
      "#chronoFreq = words2freq(chronoWords)\n",
      "#print chronoFreq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main characters in this game are **Crono**, **Marle**, **Lucca**, **Frog**, **Robo**, and **Magus**. Let's see how often they're mentioned. Print the results nicely using `.format()`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More generally, let's see what the 30 most frequent words are. What will we have to do?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def freq_dict_to_list(frequencies):\n",
      "    # Your code here\n",
      "    pass\n",
      "    \n",
      "#print freq_dict_to_list(chronoFreq)[:30]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('the', 3304), ('to', 1544), ('you', 1212), ('and', 1068), ('a', 803), ('will', 657), ('of', 585), (\"you'll\", 509), ('head', 462), ('in', 457), ('it', 360), ('that', 357), ('after', 315), ('is', 312), ('then', 291), ('see', 289), ('on', 273), ('now', 270), ('if', 257), ('go', 256), ('be', 255), ('your', 254), ('right', 242), ('for', 242), ('can', 237), ('get', 233), ('use', 225), ('here', 212), ('have', 187), ('back', 182)]\n"
       ]
      }
     ],
     "prompt_number": 133
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's make this look a little nicer by putting a wrapper on it called top30() that takes a frequency dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def top30(freqDict):\n",
      "    # Your cod here\n",
      "\n",
      "#top30(chronoFreq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1) ll: 610\n",
        "2) head: 462\n",
        "3) s: 404\n",
        "4) is: 312\n",
        "5) right: 242\n",
        "6) here: 230\n",
        "7) left: 179\n",
        "8) t: 169\n",
        "9) north: 163\n",
        "10) ad: 162\n",
        "11) room: 156\n",
        "12) chest: 153\n",
        "13) door: 147\n",
        "14) are: 133\n",
        "15) beat: 133\n",
        "16) crono: 130\n",
        "17) fight: 125\n",
        "18) talk: 116\n",
        "19) enter: 115\n",
        "20) hp: 114\n",
        "21) item: 112\n",
        "22) another: 99\n",
        "23) magic: 98\n",
        "24) down: 97\n",
        "25) save: 95\n",
        "26) next: 95\n",
        "27) lucca: 94\n",
        "28) again: 94\n",
        "29) attack: 91\n",
        "30) don: 88\n"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hmm, not super useful, given all the common words mixed in. Let's filter the 100 most common English words. (http://en.wikipedia.org/wiki/Most_common_words_in_English)\n",
      "\n",
      "1. Load the common words into a list\n",
      "2. Create a function that takes a frequency dictionary and a list, and returns a dictionary with the items listed removed\n",
      "3. Print top30() on the new dict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the common word list file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def filterFreq(freqDict, filterList):\n",
      "    # Your code here\n",
      "    pass\n",
      "\n",
      "#filteredChronoFreq = filterFreq(chronoFreq, commonList)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#top30(filteredChronoFreq)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Writing to files\n",
      "\n",
      "Let's quickly save the results of `top30()` to a new file in the working directory."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open(\"top30.txt\",\"w\")\n",
      "#f.write(top30(filteredChronoFreq)) #Fails! Can only write a string.\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We need a new version of top30()\n",
      "def top30string(freqDict):\n",
      "    # Your code here\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open(\"top30.txt\",\"w\")\n",
      "#f.write(top30string(filteredChronoFreq))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}