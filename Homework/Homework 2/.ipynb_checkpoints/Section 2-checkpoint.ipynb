{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Manipulating strings as lists\n",
      "\n",
      "Let's 1) reverse the order of the characters in a string, and 2) reverse each word in a multi-word string. Some scratch space:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alex = \"Robocop\"\n",
      "list(string.lower())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "['r', 'o', 'b', 'o', 'c', 'o', 'p']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dir(alex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_formatter_field_name_split', '_formatter_parser', 'capitalize', 'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dir([])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delslice__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "murphy = list(alex)\n",
      "print murphy\n",
      "\n",
      "murphy.reverse()\n",
      "print murphy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['R', 'o', 'b', 'o', 'c', 'o', 'p']\n",
        "['p', 'o', 'c', 'o', 'b', 'o', 'R']\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "murphystr = ''.join(murphy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "murphystr.capitalize()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "'Pocobor'"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Now make it a function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reverseString(string):\n",
      "    \"\"\"\n",
      "    Reverses the order of a string\n",
      "    \n",
      "    Arguments:\n",
      "        string (a string) to reverse\n",
      "    \n",
      "    Returns:\n",
      "        reversedStr (a string) that is reversed\n",
      "        \n",
      "    Raises:\n",
      "        nothing\n",
      "    \"\"\"\n",
      "    li = list(string.lower())\n",
      "    li.reverse()\n",
      "    reversedStr = ''.join(li)\n",
      "    if string[0].isupper():\n",
      "        return reversedStr.capitalize()\n",
      "    else:\n",
      "        return reversedStr       \n",
      "    \n",
      "if __name__ == \"__main__\":\n",
      "    print reverseString(\"testing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gnitset\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's have it do more than a single word:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def reverseWords(sentence):\n",
      "    \"\"\"\n",
      "    Reverses each token successively in a sentence (split by space)\n",
      "    \n",
      "    Arguments:\n",
      "        sentence (a string) to split and reverse\n",
      "    \n",
      "    Returns:\n",
      "        a string whole tokens are reversed\n",
      "        \n",
      "    Raises:\n",
      "        nothing\n",
      "    \"\"\"\n",
      "\n",
      "    tokens = sentence.split(\" \")\n",
      "    outStrs = []\n",
      "    for token in tokens:\n",
      "        outStrs.append(reverseString(token))\n",
      "    \n",
      "    return \" \".join(outStrs)\n",
      "    \n",
      "if __name__ == \"__main__\":\n",
      "    print \"Intended output:\"\n",
      "    print \"Eseht era eht semit erehw s'elpoep serutan era detset .ylereves\"\n",
      "    print \"Actual output:\"\n",
      "    print reverseWords(\"These are the times where people's natures are tested severely.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Intended output:\n",
        "Eseht era eht semit erehw s'elpoep serutan era detset .ylereves\n",
        "Actual output:\n",
        "Eseht era eht semit erehw s'elpoep serutan era detset .ylereves\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sorting lists by key functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Goal: Sort a list of strings by the position of the first 'e'\n",
      "\n",
      "But first, let's just sort alphabetically"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = \"Eseht era eht semit erehw s'elpoep serutan era detset .ylereves\"\n",
      "print dir(\"\")\n",
      "print dir([])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['__add__', '__class__', '__contains__', '__delattr__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getslice__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '_formatter_field_name_split', '_formatter_parser', 'capitalize', 'center', 'count', 'decode', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'index', 'isalnum', 'isalpha', 'isdigit', 'islower', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n",
        "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__delslice__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getslice__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__setslice__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = test.split(\" \")\n",
      "tokens.sort()\n",
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['.ylereves', 'Eseht', 'detset', 'eht', 'era', 'era', 'erehw', \"s'elpoep\", 'semit', 'serutan']\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens.sort(reverse=True)\n",
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['serutan', 'semit', \"s'elpoep\", 'erehw', 'era', 'era', 'eht', 'detset', 'Eseht', '.ylereves']\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def myLen(x):\n",
      "    return len(x)\n",
      "\n",
      "tokens.sort(key=myLen)\n",
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['era', 'era', 'eht', 'semit', 'erehw', 'Eseht', 'detset', 'serutan', \"s'elpoep\", '.ylereves']\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens.sort(key=lambda x: len(x))\n",
      "print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['era', 'era', 'eht', 'semit', 'erehw', 'Eseht', 'detset', 'serutan', \"s'elpoep\", '.ylereves']\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now let's make a more complex function to use as the sorting key"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sort by the following convention:\n",
      "# the location of the first 'e' in the sentence\n",
      "\n",
      "def getFirstInstance(string, substring):\n",
      "    \"\"\"\n",
      "    gets the location of the first substring in a string\n",
      "    \n",
      "    Arguments:\n",
      "        string (a string) to examine\n",
      "        substring (a string) to look for\n",
      "    \n",
      "    Returns:\n",
      "        the first index of substring\n",
      "        \n",
      "    Raises:\n",
      "        nothing\n",
      "    \"\"\"\n",
      "    return string.index(substring)\n",
      "\n",
      "def getFirstE(string):\n",
      "    return getFirstInstance(string.lower(), \"e\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test = \"Eseht era eht semit erehw s'elpoep serutan era detset .ylereves\"\n",
      "    tokens = test.split(\" \")\n",
      "    tokens.sort(key=getFirstE)\n",
      "    print tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Eseht', 'era', 'eht', 'erehw', 'era', 'semit', 'serutan', 'detset', \"s'elpoep\", '.ylereves']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "find() vs index():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test4 = \"abcde\"\n",
      "print test4.find(\"b\")\n",
      "print test4.index(\"b\")\n",
      "print test4.find(\"f\")\n",
      "print test4.index(\"f\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "substring not found",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-53-8a610386d34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtest4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mValueError\u001b[0m: substring not found"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n",
        "1\n",
        "-1\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fun with dictionaries\n",
      "\n",
      "What does this code do?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getMobyDickWords():\n",
      "    mobydick = \"\"\"Call me Ishmael. Some years ago -- never mind how long precisely--having\n",
      "little or no money in my purse, and nothing particular to interest me on\n",
      "shore, I thought I would sail about a little and see the watery part of\n",
      "the world. It is a way I have of driving off the spleen and regulating\n",
      "the circulation. Whenever I find myself growing grim about the mouth;\n",
      "whenever it is a damp, drizzly November in my soul; whenever I find\n",
      "myself involuntarily pausing before coffin warehouses, and bringing up\n",
      "the rear of every funeral I meet; and especially whenever my hypos get\n",
      "such an upper hand of me, that it requires a strong moral principle to\n",
      "prevent me from deliberately stepping into the street, and methodically\n",
      "knocking people's hats off -- then, I account it high time to get to sea\n",
      "as soon as I can. This is my substitute for pistol and ball. With a\n",
      "philosophical flourish Cato throws himself upon his sword; I quietly\n",
      "take to the ship. There is nothing surprising in this. If they but knew\n",
      "it, almost all men in their degree, some time or other, cherish very\n",
      "nearly the same feelings towards the ocean with me.\n",
      "\n",
      "There now is your insular city of the Manhattoes, belted round by\n",
      "wharves as Indian isles by coral reefs -- commerce surrounds it with\n",
      "her surf. Right and left, the streets take you waterward. Its extreme\n",
      "downtown is the battery, where that noble mole is washed by waves, and\n",
      "cooled by breezes, which a few hours previous were out of sight of land.\n",
      "Look at the crowds of water-gazers there.\"\"\"\n",
      "    normedText = mobydick.replace(\"\\n\", \" \")\n",
      "    punctuation = \";:,.?!-\"\n",
      "    for punct in punctuation:\n",
      "        normedText = normedText.replace(punct, \"\")\n",
      "    return filter(lambda x: x != \"\", normedText.split(\" \"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words = getMobyDickWords()\n",
      "print words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Call', 'me', 'Ishmael', 'Some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'preciselyhaving', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', 'I', 'thought', 'I', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', 'It', 'is', 'a', 'way', 'I', 'have', 'of', 'driving', 'off', 'the', 'spleen', 'and', 'regulating', 'the', 'circulation', 'Whenever', 'I', 'find', 'myself', 'growing', 'grim', 'about', 'the', 'mouth', 'whenever', 'it', 'is', 'a', 'damp', 'drizzly', 'November', 'in', 'my', 'soul', 'whenever', 'I', 'find', 'myself', 'involuntarily', 'pausing', 'before', 'coffin', 'warehouses', 'and', 'bringing', 'up', 'the', 'rear', 'of', 'every', 'funeral', 'I', 'meet', 'and', 'especially', 'whenever', 'my', 'hypos', 'get', 'such', 'an', 'upper', 'hand', 'of', 'me', 'that', 'it', 'requires', 'a', 'strong', 'moral', 'principle', 'to', 'prevent', 'me', 'from', 'deliberately', 'stepping', 'into', 'the', 'street', 'and', 'methodically', 'knocking', \"people's\", 'hats', 'off', 'then', 'I', 'account', 'it', 'high', 'time', 'to', 'get', 'to', 'sea', 'as', 'soon', 'as', 'I', 'can', 'This', 'is', 'my', 'substitute', 'for', 'pistol', 'and', 'ball', 'With', 'a', 'philosophical', 'flourish', 'Cato', 'throws', 'himself', 'upon', 'his', 'sword', 'I', 'quietly', 'take', 'to', 'the', 'ship', 'There', 'is', 'nothing', 'surprising', 'in', 'this', 'If', 'they', 'but', 'knew', 'it', 'almost', 'all', 'men', 'in', 'their', 'degree', 'some', 'time', 'or', 'other', 'cherish', 'very', 'nearly', 'the', 'same', 'feelings', 'towards', 'the', 'ocean', 'with', 'me', 'There', 'now', 'is', 'your', 'insular', 'city', 'of', 'the', 'Manhattoes', 'belted', 'round', 'by', 'wharves', 'as', 'Indian', 'isles', 'by', 'coral', 'reefs', 'commerce', 'surrounds', 'it', 'with', 'her', 'surf', 'Right', 'and', 'left', 'the', 'streets', 'take', 'you', 'waterward', 'Its', 'extreme', 'downtown', 'is', 'the', 'battery', 'where', 'that', 'noble', 'mole', 'is', 'washed', 'by', 'waves', 'and', 'cooled', 'by', 'breezes', 'which', 'a', 'few', 'hours', 'previous', 'were', 'out', 'of', 'sight', 'of', 'land', 'Look', 'at', 'the', 'crowds', 'of', 'watergazers', 'there']\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's make a dictionary of word frequencies, like from lecture"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frequencies = {}\n",
      "# Your code here. How do we loop through the words in the 'words' list?\n",
      "\n",
      "print frequencies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'reefs': 1, 'all': 1, 'money': 1, 'hats': 1, 'soon': 1, 'years': 1, 'stepping': 1, 'find': 2, 'before': 1, 'surf': 1, 'preciselyhaving': 1, 'methodically': 1, 'to': 5, 'deliberately': 1, 'crowds': 1, 'belted': 1, 'then': 1, 'his': 1, 'which': 1, 'get': 2, 'very': 1, 'account': 1, 'every': 1, 'nearly': 1, 'they': 1, 'world': 1, 'now': 1, 'bringing': 1, 'grim': 1, 'rear': 1, 'Right': 1, 'waterward': 1, 'upper': 1, 'previous': 1, 'where': 1, 'round': 1, 'towards': 1, 'drizzly': 1, 'streets': 1, 'some': 1, 'soul': 1, 'see': 1, 'street': 1, 'hypos': 1, 'sea': 1, 'substitute': 1, 'out': 1, 'driving': 1, 'sail': 1, 'washed': 1, 'isles': 1, 'pistol': 1, 'insular': 1, 'never': 1, 'Look': 1, 'degree': 1, 'This': 1, 'funeral': 1, 'involuntarily': 1, 'hours': 1, 'watergazers': 1, \"people's\": 1, 'strong': 1, 'by': 4, 'extreme': 1, 'on': 1, 'about': 2, 'her': 1, 'of': 8, 'coral': 1, 'cooled': 1, 'cherish': 1, 'damp': 1, 'quietly': 1, 'prevent': 1, 'battery': 1, 'into': 1, 'There': 2, 'knocking': 1, 'feelings': 1, 'philosophical': 1, 'Indian': 1, 'moral': 1, 'your': 1, 'city': 1, 'little': 2, 'from': 1, 'would': 1, 'few': 1, 'warehouses': 1, 'there': 1, 'long': 1, 'their': 1, 'interest': 1, 'November': 1, 'a': 6, 'throws': 1, 'way': 1, 'that': 2, 'Whenever': 1, 'purse': 1, 'but': 1, 'downtown': 1, 'part': 1, 'particular': 1, 'Cato': 1, 'with': 2, 'me': 5, 'commerce': 1, 'myself': 2, 'surrounds': 1, 'circulation': 1, 'this': 1, 'breezes': 1, 'up': 1, 'can': 1, 'were': 1, 'growing': 1, 'meet': 1, 'my': 4, 'coffin': 1, 'and': 9, 'sight': 1, 'wharves': 1, 'almost': 1, 'is': 7, 'mind': 1, 'it': 5, 'an': 1, 'high': 1, 'as': 3, 'himself': 1, 'Call': 1, 'at': 1, 'have': 1, 'in': 4, 'ship': 1, 'ocean': 1, 'mole': 1, 'Manhattoes': 1, 'no': 1, 'same': 1, 'for': 1, 'how': 1, 'other': 1, 'take': 2, 'sword': 1, 'you': 1, 'With': 1, 'Ishmael': 1, 'watery': 1, 'noble': 1, 'ball': 1, 'I': 9, 'knew': 1, 'upon': 1, 'hand': 1, 'pausing': 1, 'mouth': 1, 'men': 1, 'waves': 1, 'nothing': 2, 'such': 1, 'flourish': 1, 'ago': 1, 'land': 1, 'off': 2, 'especially': 1, 'surprising': 1, 'spleen': 1, 'whenever': 3, 'Some': 1, 'It': 1, 'or': 2, 'thought': 1, 'shore': 1, 'regulating': 1, 'principle': 1, 'time': 2, 'the': 14, 'left': 1, 'requires': 1, 'Its': 1, 'If': 1}\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's get the frequency of the first letters. First, how do we drill down to get at words and their frequencies in the dict we just made?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print frequencies[\"about\"]\n",
      "print \"about\"[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "a\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frequenciesLetters = {}\n",
      "\n",
      "# Your code here. Get the words from our other dictionary and make a new one for the first letters from it.\n",
      "\n",
      "print frequenciesLetters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'C': 2, 'I': 14, 'M': 1, 'L': 1, 'N': 1, 'S': 1, 'R': 1, 'T': 3, 'W': 2, 'a': 26, 'c': 9, 'b': 11, 'e': 3, 'd': 6, 'g': 4, 'f': 8, 'i': 21, 'h': 10, 'k': 2, 'm': 19, 'l': 5, 'o': 16, 'n': 7, 'q': 1, 'p': 11, 's': 21, 'r': 5, 'u': 3, 't': 33, 'w': 18, 'v': 1, 'y': 3}\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can sort frequenciesLetters by the keys (i.e., the letters) pretty easily."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "items = frequenciesLetters.items()\n",
      "print items"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('C', 2), ('I', 14), ('M', 1), ('L', 1), ('N', 1), ('S', 1), ('R', 1), ('T', 3), ('W', 2), ('a', 26), ('c', 9), ('b', 11), ('e', 3), ('d', 6), ('g', 4), ('f', 8), ('i', 21), ('h', 10), ('k', 2), ('m', 19), ('l', 5), ('o', 16), ('n', 7), ('q', 1), ('p', 11), ('s', 21), ('r', 5), ('u', 3), ('t', 33), ('w', 18), ('v', 1), ('y', 3)]\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "items.sort(reverse=True)\n",
      "print items"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('y', 3), ('w', 18), ('v', 1), ('u', 3), ('t', 33), ('s', 21), ('r', 5), ('q', 1), ('p', 11), ('o', 16), ('n', 7), ('m', 19), ('l', 5), ('k', 2), ('i', 21), ('h', 10), ('g', 4), ('f', 8), ('e', 3), ('d', 6), ('c', 9), ('b', 11), ('a', 26), ('W', 2), ('T', 3), ('S', 1), ('R', 1), ('N', 1), ('M', 1), ('L', 1), ('I', 14), ('C', 2)]\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But how can we sort by frequency?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print items[0]\n",
      "print items[0][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('y', 3)\n",
        "3\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getCounts(item):\n",
      "    return item[1]\n",
      "items.sort(key= getCounts, reverse= True)\n",
      "print items"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('t', 33), ('a', 26), ('s', 21), ('i', 21), ('m', 19), ('w', 18), ('o', 16), ('I', 14), ('p', 11), ('b', 11), ('h', 10), ('c', 9), ('f', 8), ('n', 7), ('d', 6), ('r', 5), ('l', 5), ('g', 4), ('y', 3), ('u', 3), ('e', 3), ('T', 3), ('k', 2), ('W', 2), ('C', 2), ('v', 1), ('q', 1), ('S', 1), ('R', 1), ('N', 1), ('M', 1), ('L', 1)]\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Dictionaries of dictionaries (yo dawg)\n",
      "\n",
      "The dictionary below holds verbs. Each verb is the key for a dictionary of its thematic roles. Each thematic role is a dictionary of the sentence structures that the role can appear in with the verb in question."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thetaMap = {}\n",
      "thetaMap[\"destroy\"] = {}\n",
      "thetaMap[\"destroy\"][\"Agent\"] = [(\"S\", \"NP V NP\"), (\"S\", \"NP V NP PP.INSTRUMENT\")]\n",
      "thetaMap[\"destroy\"][\"Patient\"] = [(\"S\", \"NP V NP\"), (\"S\", \"NP V NP PP.INSTRUMENT\"), (\"S\", \"PP.INSTRUMENT V NP\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thetaMap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "{'destroy': {'Agent': [('S', 'NP V NP'), ('S', 'NP V NP PP.INSTRUMENT')],\n",
        "  'Patient': [('S', 'NP V NP'),\n",
        "   ('S', 'NP V NP PP.INSTRUMENT'),\n",
        "   ('S', 'PP.INSTRUMENT V NP')]}}"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, let's use this for something. Let's see what syntactic structures involving the ver 'destroy' have both an Agent and a Patient."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def struxOverlap(verb, role1, role2):\n",
      "    \"\"\"\n",
      "    Lists possible syntactic structures containing a given verb and two given thematic arguments\n",
      "    \n",
      "    Arguments:\n",
      "        verb (string), a verb key in thetaMap\n",
      "        role1 (string), a theta role key in thetaMap[verb]\n",
      "        role2 (string), another theta role key in thetaMap[verb]\n",
      "    \n",
      "    Returns:\n",
      "        overlap (list), the structures shared by thetaMap[verb][role1] and thetaMap[verb][role2]\n",
      "        \n",
      "    Raises:\n",
      "        nothing\n",
      "    \"\"\"\n",
      "    global thetaMap\n",
      "    overlap = []\n",
      "    verbEntry = thetaMap[verb]\n",
      "    overlap = [strux for strux in verbEntry[role1] if strux in verbEntry[role2]]\n",
      "    return overlap\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print struxOverlap(\"destroy\", \"Agent\", \"Patient\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('S', 'NP V NP'), ('S', 'NP V NP PP.INSTRUMENT')]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}