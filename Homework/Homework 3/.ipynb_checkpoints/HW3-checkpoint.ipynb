{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the following series of problems, you will create a class that will load a text file from the data directory on the class site, and produce, based on that file and the CMU Pronouncing Dictionary, a phoneme *frequency table*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 1\n",
      "\n",
      "Your job in the first problem is simply to load the file, and tokenize it. The relevant files to choose are in the data/SampleTexts directory. There are two ways of saying where that is. There is the short or *relative* path, which is given from where this notebook is (homework/HW3). In such paths, to go up, one uses two periods. So, \"..\" means the parent of HW3, which is homework, and \"../..\" is the github repo root.\n",
      "\n",
      "Use relative paths to open one of the files in SampleTexts. Write another function that reads through the text, line by line, and tokenizes it. Since we are going for phonemes, you can ignore any tokens not in the CMU dictionary, including punctuation. Your tokenizer should examine the CMU dictionary and return a list of tokens, where each token is the CMU pronunciation for that word. If the word has multiple pronunciations, choose the first. If the word isn't in the dictionary, just ignore it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "import json\n",
      "\n",
      "# your code here\n",
      "# remember to use functions!\n",
      "fb = open(\"../data/SampleTexts/mountainhouses.txt\", \"r\")\n",
      "fb.close\n",
      "fd = open(\"../cmdict7a.json\", \"r\")\n",
      "fd.close\n",
      "#dictionary = json.load(fd)\n",
      "\n",
      "def tokenizer(fyle):\n",
      "    punct = \"! @ # $ % ^ & * ( ) _ - + = | \\ } ] { [ : ; > . < , ? / \" '\"\n",
      "    lines = json.dump(\n",
      "    for li in lines:\n",
      "        li = lines.split()\n",
      "        for word in li:\n",
      "            newSplit = []\n",
      "            li = lines.split(punct)\n",
      "                \n",
      "            \n",
      "\n",
      "            \n",
      "print punct\n",
      "print tokenizer(fb)\n",
      "if __name__ == \"__main__\":\n",
      "    pass #do something here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "EOL while scanning string literal (<ipython-input-16-c65c7ed238a5>, line 15)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-c65c7ed238a5>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    \"\"\"!@#$%^&*()_-\"'+=|\\}]{[:;>.<,?/\"\"\"\"\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 2\n",
      "\n",
      "Now, write another function that loops through the tokens and, for each word in turn, counts the number of times pairs of phonemes appear. Specifically, if a line was \"how much wood could a wood chuck chuck if a woodchuck could chuck wood\"\n",
      "\n",
      "with pronunciations\n",
      "\n",
      "\n",
      "[u'HH', u'AW'] [u'M', u'AH', u'CH'] [u'W', u'UH', u'D'] [u'K', u'UH', u'D'] [u'AH'] [u'W', u'UH', u'D'] [u'CH', u'AH', u'K'] [u'CH', u'AH', u'K'] [u'IH', u'F'] [u'AH'] [u'W', u'UH', u'D', u'CH', u'AH', u'K'] [u'K', u'UH', u'D'] [u'CH', u'AH', u'K'] [u'W', u'UH', u'D']\n",
      "\n",
      "we want a dict of dicts that ends up like this:\n",
      "\n",
      "{u'AH': {u'CH': 1, u'K': 4},\n",
      " u'CH': {u'AH': 4},\n",
      " u'D': {u'CH': 1},\n",
      " u'HH': {u'AW': 1},\n",
      " u'IH': {u'F': 1},\n",
      " u'K': {u'UH': 2},\n",
      " u'M': {u'AH': 1},\n",
      " u'UH': {u'D': 6},\n",
      " u'W': {u'UH': 4}}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 3\n",
      "\n",
      "Write a function that is passed that dict of dicts and arranges all of it in a nice contingency table, like the one below."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      " AH  CH   D  HH  IH   K   M  UH   W\n",
      "      1               4             AH  \n",
      "  4                                 CH  \n",
      "      1                             D   \n",
      "                                    HH  \n",
      "                                    IH  \n",
      "                              2     K   \n",
      "  1                                 M   \n",
      "          6                         UH  \n",
      "                              4     W "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 4\n",
      "\n",
      "Now, write a class called `FrequencyTable` which takes a filename as an input and automatically reads the file, tokenizes it, and stores the frequency dictionary in self.frequencies.\n",
      "\n",
      "The class should have one special method `__str__`, which returns the contingency table above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 5\n",
      "\n",
      "Extend your class to have the following special methods:\n",
      "\n",
      "1. a `__len__` method, which returns the number of phonemes encountered across the file,\n",
      "2. a `__cmp__` method, which compares two `FrequencyTable` instances by the number of phonemes that occur in each instance, and\n",
      "3. a `__getitem__` method, which returns the subdict for a given first phoneme.\n",
      "\n",
      "For each of the 5 files in the SampleTexts directory, instantiate a class, and show the lengths and contingency tables from each except. Put them in a list and sort them in reverse."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}